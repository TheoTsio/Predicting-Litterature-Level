{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ar1st\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ar1st\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1206\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1178\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1142\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m..\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDataset\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mKAROUSOU_ET_ECONOMACOU_EMERGENT_LITERACY_PREDICTION_OSF.xlsx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ar1st\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ar1st\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = engine\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ar1st\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:552\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    540\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    541\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    554\u001b[39m         filepath_or_buffer,\n\u001b[32m    555\u001b[39m         storage_options=storage_options,\n\u001b[32m    556\u001b[39m         engine_kwargs=engine_kwargs,\n\u001b[32m    557\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ar1st\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('..\\Dataset\\KAROUSOU_ET_ECONOMACOU_EMERGENT_LITERACY_PREDICTION_OSF.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the important information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target feature we want to predict is the LITERACY_3CLUSTERS. Here we try to examin the balance of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LITERACY_3CLUSTERS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts = df['LITERACY_3CLUSTERS'].value_counts()\n",
    "ax = df_value_counts.plot(kind='pie', labels=['Litteracy 2', 'Literacy 1', 'Literacy 3'])\n",
    "ax.set_ylabel('')\n",
    "\n",
    "plt.savefig(r\"..\\Results\\pie_graph_unbalancced_dataset.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the names of some columns. This happened to support the workflow of our paper. Also we group our features to 3 groups. The group A, group B and group C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP A\n",
    "df.rename(columns={'PERCENT_NONVOCAL': 'NVOC'}, inplace=True)\n",
    "df.rename(columns={'PERCENT_VOCAL': 'VOC'}, inplace=True)\n",
    "df.rename(columns={'PERCENT_COMPR': 'COMPR'}, inplace=True)\n",
    "df.rename(columns={'PERCENT_VOCAB': 'VOCAB'}, inplace=True)\n",
    "df.rename(columns={'PERCENT_MORPHOL': 'MOR'}, inplace=True)\n",
    "df.rename(columns={'PERCENT_SYNTAX': 'SYNT'}, inplace=True)\n",
    "\n",
    "# GROUP B\n",
    "df.rename(columns={'TOTAL_HLE': 'HLE'}, inplace=True)\n",
    "df.rename(columns={'TOTAL_ISBR': 'ISBR'}, inplace=True)\n",
    "df.rename(columns={'EDUCATION_1': 'EDU_M'}, inplace=True)\n",
    "df.rename(columns={'HOURSMOTHER': 'HRS_M'}, inplace=True)\n",
    "df.rename(columns={'hoursworkmother': 'HRSWORK_M'}, inplace=True)\n",
    "df.rename(columns={'WORKSTATUS_1': 'WSTATUS_M'}, inplace=True)\n",
    "df.rename(columns={'NR_CHILDREN': 'NRCHILD'}, inplace=True)\n",
    "df.rename(columns={'URBANITY': 'URB'}, inplace=True)\n",
    "df.rename(columns={'NRBOOKS': 'NRBOOKS'}, inplace=True)\n",
    "df.rename(columns={'ECONOMIC': 'ECONOMIC'}, inplace=True)\n",
    "df.rename(columns={'EDUCATION_2': 'EDU_F'}, inplace=True)\n",
    "df.rename(columns={'HOURSFATHER': 'HRS_F'}, inplace=True)\n",
    "df.rename(columns={'hoursworkfather': 'HRSWORK_F'}, inplace=True)\n",
    "df.rename(columns={'WORKSTATUS_2': 'WSTATUS_F'}, inplace=True)\n",
    "df.rename(columns={'BIRTHORDER': 'BIRTHORDER'}, inplace=True)\n",
    "\n",
    "# GROUP C\n",
    "df.rename(columns={'GENDER': 'SEX'}, inplace=True)\n",
    "df.rename(columns={'BIRTHWEIGHT': 'BIRTHWEIGHT'}, inplace=True)\n",
    "df.rename(columns={'PREMAWEEK': 'GESTWEEK'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_A = ['NVOC', 'VOC', 'COMPR', 'VOCAB', 'MOR', 'SYNT']\n",
    "group_B = ['HLE', 'ISBR', 'EDU_M', 'HRS_M', 'HRSWORK_M', 'WSTATUS_M', 'NRCHILD', 'URB', 'NRBOOKS', 'ECONOMIC', 'EDU_F', 'HRS_F', 'HRSWORK_F', 'WSTATUS_F', 'BIRTHORDER']\n",
    "group_C = ['BIRTHWEIGHT', 'GESTWEEK', 'SEX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the columns from this dataset to use for the training. In each experiment we define a different subset of the Features. So change the next cell to choose different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the subset that predicts the best results.\n",
    "df = df[['AGE'] + group_A + ['HRS_M', 'HRS_F', 'HRSWORK_M'] + ['LITERACY_3CLUSTERS']] \n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pycaret to train and assess instantly 13 models. This give us the chance to see in each experiment the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Setup / We se a session_id=123 which is the random seep to ensure that our experiments is reproducible\n",
    "clf = setup(data=df, target='LITERACY_3CLUSTERS', train_size=0.75, session_id=123, verbose=False, normalize=True)\n",
    "\n",
    "# Step 2: Train and pick best model\n",
    "best_model = compare_models()\n",
    "\n",
    "# Step 3: Evaluate on the holdout set (25% of data)\n",
    "predictions = predict_model(best_model)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions['LITERACY_3CLUSTERS'], predictions['prediction_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pycaret performs an automated data preprocessing. So we want to see the best model's hyperparameters and the pipeline of data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_config('pipeline') # The output is the data preprocessing workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Partial Dependency Plot for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define number of classes and feature to plot\n",
    "n_classes = 3\n",
    "feature = \"AGE\"\n",
    "class_labels = [\"Class 0\", \"Class 1\", \"Class 2\"]\n",
    "\n",
    "# Get transformed training data\n",
    "X_train_transformed = get_config('X_train_transformed')\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, n_classes, figsize=(5 * n_classes, 4), constrained_layout=True)\n",
    "\n",
    "# Generate PDPs and add titles using display.axes_\n",
    "for class_idx in range(n_classes):\n",
    "    display = PartialDependenceDisplay.from_estimator(\n",
    "        estimator=best_model,\n",
    "        X=X_train_transformed,\n",
    "        features=[feature],\n",
    "        target=class_idx,\n",
    "        grid_resolution=50,\n",
    "        ax=axs[class_idx]\n",
    "    )\n",
    "    \n",
    "    # Overwrite title using display.axes_\n",
    "    display.axes_[0, 0].set_title(f\"Partial Dependence â€“ {class_labels[class_idx]}\")\n",
    "    display.axes_[0, 0].set_xlabel(\"AGE\")\n",
    "    display.axes_[0, 0].set_ylabel(\"Predicted Probability\")\n",
    "\n",
    "# Save to PDF\n",
    "plt.savefig(\"..\\Results\\Partial_Dependence_AGE_T2_All_Classes.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute SHAP for Class 0 and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m max_display=\u001b[32m10\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_display=10\n",
    "\n",
    "# Get transformed training data\n",
    "X_train_transformed = get_config('X_train_transformed')\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_train_transformed)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert the list into a single NumPy array\n",
    "shap_values_array = np.stack(shap_values)  # Now should be (171, 22, 3)\n",
    "\n",
    "# Choose a class index (e.g., class 1)\n",
    "class_index = 0\n",
    "shap_values_class = shap_values_array[:, :, class_index]  # (171, 22)\n",
    "\n",
    "# Now plot\n",
    "shap.summary_plot(shap_values_class, X_train_transformed, plot_type=\"dot\", max_display=max_display, show=False)\n",
    "# Grab the current figure and save\n",
    "plt.savefig(\"..\\Results\\Shapley_Value_Best_Model_Class_0.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute SHAP for Class 1 and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_display=10\n",
    "\n",
    "# Get transformed training data\n",
    "X_train_transformed = get_config('X_train_transformed')\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_train_transformed)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert the list into a single NumPy array\n",
    "shap_values_array = np.stack(shap_values)  # Now should be (171, 22, 3)\n",
    "\n",
    "# Choose a class index (e.g., class 1)\n",
    "class_index = 1\n",
    "shap_values_class = shap_values_array[:, :, class_index]  # (171, 22)\n",
    "\n",
    "# Now plot\n",
    "shap.summary_plot(shap_values_class, X_train_transformed, plot_type=\"dot\", max_display=max_display, show=False)\n",
    "# Grab the current figure and save\n",
    "plt.savefig(\"..\\Results\\Shapley_Value_Best_Model_Class_1.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute SHAP for Class 2 and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_display=10\n",
    "\n",
    "# Get transformed training data\n",
    "X_train_transformed = get_config('X_train_transformed')\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_train_transformed)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert the list into a single NumPy array\n",
    "shap_values_array = np.stack(shap_values)  # Now should be (171, 22, 3)\n",
    "\n",
    "# Choose a class index (e.g., class 1)\n",
    "class_index = 2\n",
    "shap_values_class = shap_values_array[:, :, class_index]  # (171, 22)\n",
    "\n",
    "# Now plot\n",
    "shap.summary_plot(shap_values_class, X_train_transformed, plot_type=\"dot\", max_display=max_display, show=False)\n",
    "# Grab the current figure and save\n",
    "plt.savefig(\"..\\Results\\Shapley_Value_Best_Model_Class_2.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
